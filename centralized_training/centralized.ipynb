{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec71758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c88292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   traffic_load  num_users  packet_count  avg_packet_size  allocated_bandwidth\n",
      "0      0.017677      0.375           0.0         0.004402             0.017677\n",
      "1      0.028851      0.625           0.0         0.000000             0.028851\n",
      "2      0.044450      0.375           0.0         0.014374             0.044450\n",
      "3      0.023949      0.750           0.0         0.006602             0.023949\n",
      "4      0.258286      0.625           0.0         0.034113             0.258286\n",
      "(785, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\YASH\\\\Documents\\\\GitHub\\\\A-Decentralized-Framework-for-AI-based-Resource-Allocation-in-Open-RAN\\\\data\\\\final_ran_dataset.csv\")\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d30d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['traffic_load', 'num_users', 'packet_count', 'avg_packet_size']].values\n",
    "y = df['allocated_bandwidth'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5da6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e4a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentralizedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b7b8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CentralizedModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d4f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "151e3a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0088\n",
      "Epoch [2/30], Loss: 0.0055\n",
      "Epoch [3/30], Loss: 0.0048\n",
      "Epoch [4/30], Loss: 0.0048\n",
      "Epoch [5/30], Loss: 0.0041\n",
      "Epoch [6/30], Loss: 0.0038\n",
      "Epoch [7/30], Loss: 0.0037\n",
      "Epoch [8/30], Loss: 0.0034\n",
      "Epoch [9/30], Loss: 0.0031\n",
      "Epoch [10/30], Loss: 0.0029\n",
      "Epoch [11/30], Loss: 0.0026\n",
      "Epoch [12/30], Loss: 0.0024\n",
      "Epoch [13/30], Loss: 0.0022\n",
      "Epoch [14/30], Loss: 0.0019\n",
      "Epoch [15/30], Loss: 0.0017\n",
      "Epoch [16/30], Loss: 0.0015\n",
      "Epoch [17/30], Loss: 0.0013\n",
      "Epoch [18/30], Loss: 0.0011\n",
      "Epoch [19/30], Loss: 0.0010\n",
      "Epoch [20/30], Loss: 0.0008\n",
      "Epoch [21/30], Loss: 0.0007\n",
      "Epoch [22/30], Loss: 0.0006\n",
      "Epoch [23/30], Loss: 0.0005\n",
      "Epoch [24/30], Loss: 0.0004\n",
      "Epoch [25/30], Loss: 0.0003\n",
      "Epoch [26/30], Loss: 0.0003\n",
      "Epoch [27/30], Loss: 0.0002\n",
      "Epoch [28/30], Loss: 0.0002\n",
      "Epoch [29/30], Loss: 0.0002\n",
      "Epoch [30/30], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b17267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.952213177806698e-05\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "\n",
    "print(\"Test MSE:\", test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fff12e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized baseline model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"centralized_results.pth\")\n",
    "print(\"Centralized baseline model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
